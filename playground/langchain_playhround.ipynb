{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bf9977",
   "metadata": {},
   "source": [
    "# LangChain Playground\n",
    "\n",
    "This is a simple LangChain playground notebook to experiment with the framework and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054d6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import LLm providers\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad65411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dotenv files\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file from current directory (playground folder)\n",
    "env_path = os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# load environment variables\n",
    "OPENAI_APIKEY = os.getenv('OPENAI_APIKEY', '')\n",
    "\n",
    "# Claude API Configuration\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '')\n",
    "DEFAULT_MODEL = os.getenv('DEFAULT_MODEL', 'claude-3-haiku-20240307')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a45d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain imports\n",
    "from langchain_anthropic import ChatAnthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test for langchain\n",
    "\n",
    "# Create Anthropic LLM instance\n",
    "llm = ChatAnthropic(\n",
    "    model=DEFAULT_MODEL,\n",
    "    api_key=ANTHROPIC_API_KEY,\n",
    "    temperature=0.8,\n",
    "    max_tokens=2500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the LLM with a simple prompt\n",
    "response = llm.invoke(\"What is LangChain and how does it work?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9219ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Beef Burger\n",
      "\n",
      "## Complexity Level\n",
      "\n",
      "Easy\n",
      "\n",
      "### Ingredients\n",
      "\n",
      "- 500g ground beef\n",
      "- 4 burger buns\n",
      "- 4 slices of cheese (e.g., cheddar, Swiss)\n",
      "- 1 tomato, sliced\n",
      "- 1 onion, sliced\n",
      "- 4 lettuce leaves\n",
      "- 2 tbsp mayonnaise\n",
      "- 2 tsp mustard\n",
      "- Salt and pepper to taste\n",
      "\n",
      "### Instructions\n",
      "\n",
      "1. Prepare the burger:\n",
      "   - Divide the ground beef into 4 equal portions and shape them into patties, about 1 cm thick.\n",
      "   - Season the patties with salt and pepper.\n",
      "\n",
      "2. Cook the burger according to your preferred method:\n",
      "   - You can grill, pan-fry, or bake the patties until they reach your desired level of doneness.\n",
      "\n",
      "3. Serve the burger:\n",
      "   - Toast the burger buns.\n",
      "   - Spread mayonnaise and mustard on the bottom bun.\n",
      "   - Place the cooked burger patty on the bottom bun.\n",
      "   - Top with a slice of cheese, tomato slices, onion slices, and a lettuce leaf.\n",
      "   - Close the burger with the top bun.\n",
      "   - Serve the burgers with your choice of sides, such as fries, salad, or chips.\n",
      "\n",
      "Enjoy your homemade beef burger!\n"
     ]
    }
   ],
   "source": [
    "# Langchain chain example\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# ask question to user\n",
    "response = input(\"\\nWhat is your favourite food?\").lower().strip()\n",
    "\n",
    "first_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"\"\"\n",
    "      You are a chef-cook and your task is to create a recipe for {input}.\n",
    "      Please provide a simplified recipe including ingredients and simple instructions.\n",
    "      Use euro-style measurements (e.g., grams, liters).\n",
    "\n",
    "      Output the recipe in a structured format.\n",
    "\n",
    "      ### Title\n",
    "\n",
    "      ### Ingredients\n",
    "    \n",
    "      ### Instructions\n",
    "      1. Prepare the {input}.\n",
    "      2. Cook the {input} according to your preferred method.\n",
    "      3. Serve the {input} with your choice of sides.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "first_chain = LLMChain(\n",
    "          llm=llm,\n",
    "          prompt=first_prompt\n",
    "        )\n",
    "\n",
    "# # Run the chain with the user's response\n",
    "# first_chain.run(input=response)\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "  input_variables=[\"input\"],\n",
    "  template=\"\"\"\n",
    "    Identify the complexity for the recipe of {input}.\n",
    "\n",
    "    Output the following structure\n",
    "\n",
    "    # Recipe title\n",
    "\n",
    "    ## Complexity Level\n",
    "\n",
    "    {input}\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "second_chain = LLMChain(\n",
    "          llm=llm,\n",
    "          prompt=second_prompt\n",
    "        )\n",
    "\n",
    "# Combine the first and the second chain \n",
    "overall_chain = SimpleSequentialChain(chains=[first_chain, second_chain], verbose=False)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "catchphrase = overall_chain.run(input=response)\n",
    "\n",
    "print(catchphrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e3a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
